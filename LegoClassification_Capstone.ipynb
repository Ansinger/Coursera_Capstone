{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Configurations</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import albumentations as A\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import mobilenet_v2 as tf_mobilenet_v2\n",
    "from tensorflow.keras import layers as tf_layers\n",
    "from tensorflow.keras import models as tf_models\n",
    "from tensorflow.keras import callbacks as tf_callbacks\n",
    "from sklearn import metrics as sk_metrics\n",
    "from sklearn import model_selection as sk_model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The directory to the dataset\n",
    "BASE_DIR = '../input/lego-minifigures-classification/'\n",
    "PATH_INDEX = os.path.join(BASE_DIR, \"index.csv\")\n",
    "PATH_TEST = os.path.join(BASE_DIR, \"test.csv\")\n",
    "PATH_METADATA = os.path.join(BASE_DIR, \"metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"seed\": 42,\n",
    "    \n",
    "    \"valid_size\": 0.3,\n",
    "    \n",
    "    \"image_size\": (512, 512),\n",
    "    \"train_batch_size\": 4,\n",
    "    \"valid_batch_size\": 1,\n",
    "    \"test_batch_size\": 1,\n",
    "    \n",
    "    \"model\": \"mobilenet_v2\",\n",
    "    \"max_epochs\": 50,\n",
    "    \"patience_stop\": 3,\n",
    "    \"path_to_save_model\": \"best.hdf5\",\n",
    "    \"callbacks_monitor\": \"val_loss\",\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to set random seet that our experiment repeated between (We have some problem to set seed with GPU)\n",
    "def set_seed(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    tf.random.set_seed(seed_value)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed_value)\n",
    "    os.environ[\"TF_DETERMINISTIC_OPS\"] = \"true\"\n",
    "    \n",
    "\n",
    "set_seed(config[\"seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data reading</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read information about dataset\n",
    "df = pd.read_csv(PATH_INDEX)\n",
    "\n",
    "tmp_train, tmp_valid = sk_model_selection.train_test_split(\n",
    "    df, test_size=config[\"valid_size\"], random_state=config[\"seed\"], stratify=df['class_id']\n",
    ")\n",
    "\n",
    "# Get train file paths\n",
    "train_paths = tmp_train['path'].values\n",
    "# Get train labels\n",
    "train_targets = tmp_train['class_id'].values\n",
    "# Create full train paths (base dir + concrete file)\n",
    "train_paths = list(map(lambda x: os.path.join(BASE_DIR, x), train_paths))\n",
    "\n",
    "# Get valid file paths\n",
    "valid_paths = tmp_valid['path'].values\n",
    "# Get valid labels\n",
    "valid_targets = tmp_valid['class_id'].values\n",
    "# Create full valid paths (base dir + concrete file)\n",
    "valid_paths = list(map(lambda x: os.path.join(BASE_DIR, x), valid_paths))\n",
    "\n",
    "df_test = pd.read_csv(PATH_TEST)\n",
    "test_paths = df_test['path'].values\n",
    "test_paths = list(map(lambda x: os.path.join(BASE_DIR, x), test_paths))\n",
    "test_targets = df_test['class_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of classes in the dataset\n",
    "df_metadata = pd.read_csv(PATH_METADATA)\n",
    "n_classes = df_metadata.shape[0]\n",
    "print('Number of classes: ', n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data generator</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataGenerator allows you not to load the entire dataset to memory at once, but to do it in batches   \n",
    "# Each time we have only one batch of pictures in memory\n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(\n",
    "        self, \n",
    "        paths, \n",
    "        targets, \n",
    "        image_size=(224, 224), \n",
    "        batch_size=64, \n",
    "        shuffle=True, \n",
    "        transforms=None\n",
    "    ):\n",
    "        # the list of paths to files\n",
    "        self.paths = paths\n",
    "        # the list with the true labels of each file\n",
    "        self.targets = targets\n",
    "        # images size\n",
    "        self.image_size = image_size\n",
    "        # batch size (the number of images)\n",
    "        self.batch_size = batch_size\n",
    "        # if we need to shuffle order of files\n",
    "        # for validation we don't need to shuffle, for training - do\n",
    "        self.shuffle = shuffle\n",
    "        # Augmentations for our images. It is implemented with albumentations library\n",
    "        self.transforms = transforms\n",
    "        # Preprocess function for the pretrained model. \n",
    "        # CHANGE IT IF USING OTHER THAN MOBILENETV2 MODEL\n",
    "        self.preprocess = tf_mobilenet_v2.preprocess_input\n",
    "        \n",
    "        # Call function to create and shuffle (if needed) indices of files\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        # This function is called at the end of each epoch while training\n",
    "        \n",
    "        # Create as many indices as many files we have\n",
    "        self.indexes = np.arange(len(self.paths))\n",
    "        # Shuffle them if needed\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "    def __len__(self):\n",
    "        # We need that this function returns the number of steps in one epoch\n",
    "        \n",
    "        # How many batches we have\n",
    "        return len(self.paths) // self.batch_size\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # This function returns batch of pictures with their labels\n",
    "        \n",
    "        # Take in order as many indices as our batch size is\n",
    "        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "        \n",
    "        # Take image file paths that are included in that batch\n",
    "        batch_paths = [self.paths[k] for k in indexes]\n",
    "        # Take labels for each image\n",
    "        batch_y = [self.targets[k] - 1 for k in indexes]\n",
    "        batch_X = []\n",
    "        for i in range(self.batch_size):\n",
    "            # Read the image\n",
    "            img = cv2.imread(batch_paths[i])\n",
    "            # Resize it to needed shape\n",
    "            img = cv2.resize(img, self.image_size)\n",
    "            # Convert image colors from BGR to RGB\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            # Apply transforms (see albumentations library)\n",
    "            if self.transforms:\n",
    "                img = self.transforms(image=img)['image']\n",
    "            # Normalize image\n",
    "#             img = img / 255.\n",
    "            img = self.preprocess(img)\n",
    "            \n",
    "            batch_X.append(img)\n",
    "            \n",
    "        return np.array(batch_X), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Augmentations </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# albumentations transformations for training data. We don't need this transformations for the validation\n",
    "\n",
    "def get_train_transforms():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Rotate(limit=30, border_mode=cv2.BORDER_REPLICATE, p=0.5),\n",
    "            A.Cutout(num_holes=8, max_h_size=25, max_w_size=25, fill_value=0, p=0.25),\n",
    "            A.Cutout(num_holes=8, max_h_size=25, max_w_size=25, fill_value=255, p=0.25),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.RandomContrast(limit=(-0.3, 0.3), p=0.5),\n",
    "            A.RandomBrightness(limit=(-0.4, 0.4), p=0.5),\n",
    "            A.Blur(p=0.25),\n",
    "        ], \n",
    "        p=1.0\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Train and valid generators</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the train data generator\n",
    "train_generator = DataGenerator(\n",
    "    train_paths, \n",
    "    train_targets, \n",
    "    batch_size=config[\"train_batch_size\"], \n",
    "    image_size=config[\"image_size\"],\n",
    "    shuffle=True, \n",
    "    transforms=get_train_transforms()\n",
    ")\n",
    "\n",
    "# Initialize the valid data generator\n",
    "valid_generator = DataGenerator(\n",
    "    valid_paths, \n",
    "    valid_targets, \n",
    "    image_size=config[\"image_size\"],\n",
    "    batch_size=config[\"valid_batch_size\"], \n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data visualizations (train samples)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_image(image):\n",
    "    return ((image + 1) * 127.5).astype(int)\n",
    "\n",
    "# Let's visualize some batches of the train data\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i_batch in range(4):\n",
    "    images, labels = train_generator[i_batch]\n",
    "    for i in range(4):\n",
    "        plt.subplot(4, 4, 4 * i_batch + i + 1)\n",
    "        plt.imshow(denormalize_image(images[i]))\n",
    "        plt.title(labels[i])\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data visualizations (valid samples)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize some batches of the valid data\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i_batch in range(16):\n",
    "    images, labels = valid_generator[i_batch]\n",
    "    plt.subplot(4, 4, i_batch + 1)\n",
    "    plt.imshow(denormalize_image(images[0]))\n",
    "    plt.title(labels[0])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model initialization</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_classes):\n",
    "    # We take pretrained MobileNetV2 (see Keras docs)\n",
    "    base_model = tf_mobilenet_v2.MobileNetV2()\n",
    "    x = base_model.layers[-2].output\n",
    "    # Take penultimate layer of the MobileNetV2 model and connect this layer with Dropout\n",
    "    x = tf_layers.Dropout(.5)(x)\n",
    "    # Add additional Dense layer, with number of neurons as number of our classes\n",
    "    # Use softmax activation because we have one class classification problem\n",
    "    outputs = tf_layers.Dense(n_classes, activation='softmax')(x)\n",
    "    # Create model using MobileNetV2 input and our created output\n",
    "    model = tf_models.Model(base_model.inputs, outputs)\n",
    "\n",
    "\n",
    "    # Compile model using Adam optimizer and categorical crossentropy loss\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(0.0001),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h1>Checkpoints initialization</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint to saving the best model by validation loss\n",
    "callback_save = tf_callbacks.ModelCheckpoint(\n",
    "    config[\"path_to_save_model\"],\n",
    "    monitor=config[\"callbacks_monitor\"],\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "# checkpoint to stop training if model didn't improve valid loss for 3 epochs\n",
    "callback_early_stopping = tf_callbacks.EarlyStopping(\n",
    "    monitor=config[\"callbacks_monitor\"],\n",
    "    patience=config[\"patience_stop\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model training</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(n_classes)\n",
    "\n",
    "# Train model using data generators\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=valid_generator,\n",
    "    epochs=config[\"max_epochs\"],\n",
    "    callbacks=[\n",
    "        callback_save, \n",
    "        callback_early_stopping\n",
    "    ],\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Train logs</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize train and valid loss \n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='valid loss')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.xlabel(\"Epoch number\", fontsize=15)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.ylabel(\"Loss value\", fontsize=15)\n",
    "plt.legend(fontsize=15)\n",
    "plt.grid()\n",
    "\n",
    "# Visualize train and valid accyracy \n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='train acc')\n",
    "plt.plot(history.history['val_accuracy'], label='valid acc')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.xlabel(\"Epoch number\", fontsize=15)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.ylabel(\"Accuracy score\", fontsize=15)\n",
    "plt.legend(fontsize=15)\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Final test check</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model (we create for checkpoint to save the best model)\n",
    "model = tf_models.load_model(config[\"path_to_save_model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = DataGenerator(\n",
    "    test_paths, \n",
    "    test_targets, \n",
    "    image_size=config[\"image_size\"],\n",
    "    batch_size=config[\"test_batch_size\"], \n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model predictions and true labels\n",
    "y_pred = []\n",
    "y_test = []\n",
    "for _X_test, _y_test in test_generator:\n",
    "    y_pred.extend(model.predict(_X_test).argmax(axis=-1))\n",
    "    y_test.extend(_y_test)\n",
    "\n",
    "# Calculate needed metrics\n",
    "print(f'Accuracy score on test data:  {sk_metrics.accuracy_score(y_test, y_pred)}')\n",
    "print(f'Macro F1 score on test data:  {sk_metrics.f1_score(y_test, y_pred, average=\"macro\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Error analysis - Confusion matrix</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata to get classes people-friendly names\n",
    "labels = df_metadata['minifigure_name'].tolist()\n",
    "\n",
    "# Calculate confusion matrix\n",
    "confusion_matrix = sk_metrics.confusion_matrix(y_test, y_pred)\n",
    "# confusion_matrix = confusion_matrix / confusion_matrix.sum(axis=1)\n",
    "df_confusion_matrix = pd.DataFrame(confusion_matrix, index=labels, columns=labels)\n",
    "\n",
    "# Show confusion matrix\n",
    "plt.figure(figsize=(12, 12))\n",
    "sn.heatmap(df_confusion_matrix, annot=True, cbar=False, cmap='Oranges', linewidths=1, linecolor='black')\n",
    "plt.xlabel('Predicted labels', fontsize=15)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.ylabel('True labels', fontsize=15)\n",
    "plt.yticks(fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
